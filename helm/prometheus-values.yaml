# 📊 Prometheus Configuration for K8s Auto-Heal Monitoring
# 🚀 Updated via GitOps Webhook - 2025-09-23

# Global configuration
global:
  scrape_interval: 15s
  evaluation_interval: 15s

# Prometheus server configuration
server:
  # Resource limits
  resources:
    limits:
      cpu: 2000m
      memory: 4Gi
    requests:
      cpu: 100m
      memory: 512Mi
  
  # Data retention
  retention: 15d
  
  # Persistent volume
  persistentVolume:
    enabled: true
    size: 10Gi
    storageClass: standard

# AlertManager configuration
alertmanager:
  enabled: true
  
  # Resource limits
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 50m
      memory: 64Mi
  
  # AlertManager configuration
  config:
    global:
      smtp_smarthost: 'smtp.gmail.com:587'
      smtp_from: 'sandeep.opensearch@gmail.com'
      smtp_auth_username: 'sandeep.opensearch@gmail.com'
      smtp_auth_password: 'your-app-password'
      smtp_require_tls: true

    # Alert routing configuration
    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'web.hook'
      routes:
      - match:
          severity: critical
        receiver: 'critical-alerts'
        group_wait: 5s
        repeat_interval: 30m
      - match:
          severity: warning
        receiver: 'warning-alerts'
        group_wait: 30s
        repeat_interval: 2h

    # Alert receivers
    receivers:
    - name: 'web.hook'
      webhook_configs:
      - url: 'http://localhost:5002/webhook'
        send_resolved: true

    - name: 'critical-alerts'
      email_configs:
      - to: 'sandeep.opensearch@gmail.com'
        subject: '🚨 CRITICAL: {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}

          Labels:
          {{ range .Labels.SortedPairs }}
            {{ .Name }}: {{ .Value }}
          {{ end }}

          Runbook: {{ .Annotations.runbook_url }}
          Dashboard: {{ .Annotations.dashboard_url }}
          {{ end }}
      webhook_configs:
      - url: 'http://localhost:5002/critical'
        send_resolved: true
      - url: 'http://localhost:5003/webhook'
        send_resolved: true

    - name: 'warning-alerts'
      email_configs:
      - to: 'sandeep.opensearch@gmail.com'
        subject: '⚠️ WARNING: {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}

          Labels:
          {{ range .Labels.SortedPairs }}
            {{ .Name }}: {{ .Value }}
          {{ end }}

          Runbook: {{ .Annotations.runbook_url }}
          Dashboard: {{ .Annotations.dashboard_url }}
          {{ end }}
      webhook_configs:
      - url: 'http://localhost:5002/warning'
        send_resolved: true
      - url: 'http://localhost:5003/webhook'
        send_resolved: true

    # Inhibit rules to prevent spam
    inhibit_rules:
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      equal: ['alertname', 'cluster', 'service']

  # Persistent volume for AlertManager
  persistence:
    enabled: true
    size: 2Gi

# Node Exporter
prometheus-node-exporter:
  enabled: true
  
  # Resource limits
  resources:
    limits:
      cpu: 50m
      memory: 32Mi
    requests:
      cpu: 25m
      memory: 16Mi

# Kube State Metrics
kube-state-metrics:
  enabled: true
  
  # Resource limits
  resources:
    limits:
      cpu: 100m
      memory: 64Mi
    requests:
      cpu: 50m
      memory: 32Mi

# Pushgateway
prometheus-pushgateway:
  enabled: true
  
  # Resource limits
  resources:
    limits:
      cpu: 50m
      memory: 32Mi
    requests:
      cpu: 25m
      memory: 16Mi

# Additional scrape configs for K8s Auto-Heal
extraScrapeConfigs: |
  - job_name: 'k8s-auto-heal'
    kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
            - helm
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name]
        action: keep
        regex: k8s-auto-heal
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__

# Additional alert rules
ruleFiles:
  k8s-auto-heal-rules.yml: |
    groups:
      - name: k8s.auto-heal
        rules:
          - alert: PodCrashLooping
            expr: rate(kube_pod_container_status_restarts_total[15m]) * 60 * 15 > 5
            for: 5m
            labels:
              severity: warning
              service: k8s-auto-heal
            annotations:
              summary: "Pod {{ $labels.pod }} is crash looping"
              description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} has restarted {{ $value }} times in the last 15 minutes."
          
          - alert: PodOOMKilled
            expr: increase(kube_pod_container_status_terminated_reason{reason="OOMKilled"}[5m]) > 0
            for: 0m
            labels:
              severity: critical
              service: k8s-auto-heal
            annotations:
              summary: "Pod {{ $labels.pod }} was OOMKilled"
              description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} was killed due to out of memory."
          
          - alert: PodPending
            expr: kube_pod_status_phase{phase="Pending"} == 1
            for: 10m
            labels:
              severity: warning
              service: k8s-auto-heal
            annotations:
              summary: "Pod {{ $labels.pod }} is pending"
              description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} has been in pending state for more than 10 minutes."
          
          - alert: HighMemoryUsage
            expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 80
            for: 5m
            labels:
              severity: warning
              service: k8s-auto-heal
            annotations:
              summary: "High memory usage for container {{ $labels.container }}"
              description: "Container {{ $labels.container }} in pod {{ $labels.pod }} is using {{ $value }}% of its memory limit."
          
          - alert: HighCPUUsage
            expr: (rate(container_cpu_usage_seconds_total[5m]) / container_spec_cpu_quota * container_spec_cpu_period) * 100 > 80
            for: 5m
            labels:
              severity: warning
              service: k8s-auto-heal
            annotations:
              summary: "High CPU usage for container {{ $labels.container }}"
              description: "Container {{ $labels.container }} in pod {{ $labels.pod }} is using {{ $value }}% of its CPU limit."