# Prometheus Alert Rules for Kubernetes
# This file contains alert rules for monitoring Kubernetes cluster health

groups:
  - name: kubernetes-memory-alerts
    rules:
      # OOM (Out of Memory) Alert - Most Critical
      - alert: PodOOMKilled
        expr: increase(kube_pod_container_status_restarts_total{reason="OOMKilled"}[5m]) > 0
        for: 0m
        labels:
          severity: critical
          category: memory
          service: kubernetes
          team: platform
        annotations:
          summary: "üö® CRITICAL: Pod {{ $labels.pod }} was OOMKilled"
          description: |
            Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} was killed due to Out of Memory (OOM).
            
            **Container:** {{ $labels.container }}
            **Node:** {{ $labels.node }}
            **Timestamp:** {{ $value | timestamp }}
            
            **Possible Causes:**
            - Memory limit too low for the workload
            - Memory leak in the application
            - Sudden spike in memory usage
            
            **Immediate Actions:**
            1. Check pod logs: `kubectl logs {{ $labels.pod }} -n {{ $labels.namespace }}`
            2. Review memory limits: `kubectl describe pod {{ $labels.pod }} -n {{ $labels.namespace }}`
            3. Consider increasing memory limits or fixing memory leaks
          
          runbook_url: "https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/"
          dashboard_url: "http://localhost:9090/graph?g0.expr=kube_pod_container_status_restarts_total%7Breason%3D%22OOMKilled%22%7D&g0.tab=1"

      # High Memory Usage Alert - Early Warning
      - alert: PodHighMemoryUsage
        expr: (container_memory_working_set_bytes{container!="POD",container!=""} / container_spec_memory_limit_bytes) > 0.9
        for: 2m
        labels:
          severity: warning
          category: memory
          service: kubernetes
          team: platform
        annotations:
          summary: "‚ö†Ô∏è WARNING: Pod {{ $labels.pod }} has high memory usage"
          description: |
            Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its memory limit.
            
            **Container:** {{ $labels.container }}
            **Node:** {{ $labels.node }}
            **Current Usage:** {{ $value | humanizePercentage }}
            
            **Risk:** This may lead to OOMKilled if usage continues to increase.
            
            **Recommended Actions:**
            1. Monitor memory usage trends
            2. Consider increasing memory limits
            3. Investigate for potential memory leaks
          
          runbook_url: "https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/"

      # Very High Memory Usage Alert - Critical Warning
      - alert: PodVeryHighMemoryUsage
        expr: (container_memory_working_set_bytes{container!="POD",container!=""} / container_spec_memory_limit_bytes) > 0.95
        for: 1m
        labels:
          severity: critical
          category: memory
          service: kubernetes
          team: platform
        annotations:
          summary: "üö® CRITICAL: Pod {{ $labels.pod }} has very high memory usage"
          description: |
            Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its memory limit.
            
            **Container:** {{ $labels.container }}
            **Node:** {{ $labels.node }}
            **Current Usage:** {{ $value | humanizePercentage }}
            
            **IMMEDIATE ACTION REQUIRED:** Pod is at risk of being OOMKilled soon.
            
            **Immediate Actions:**
            1. Scale up the deployment if possible
            2. Increase memory limits immediately
            3. Check for memory leaks or runaway processes
          
          runbook_url: "https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/"

  - name: kubernetes-pod-health-alerts
    rules:
      # Pod CrashLoopBackOff Alert
      - alert: PodCrashLoopBackOff
        expr: kube_pod_status_phase{phase="Running"} == 0 and kube_pod_status_phase{phase="Pending"} == 0 and kube_pod_status_phase{phase="Succeeded"} == 0 and kube_pod_status_phase{phase="Failed"} == 0
        for: 5m
        labels:
          severity: warning
          category: pod-health
          service: kubernetes
          team: platform
        annotations:
          summary: "‚ö†Ô∏è WARNING: Pod {{ $labels.pod }} is in CrashLoopBackOff"
          description: |
            Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is repeatedly crashing and restarting.
            
            **Namespace:** {{ $labels.namespace }}
            **Node:** {{ $labels.node }}
            
            **Recommended Actions:**
            1. Check pod logs: `kubectl logs {{ $labels.pod }} -n {{ $labels.namespace }} --previous`
            2. Check pod events: `kubectl describe pod {{ $labels.pod }} -n {{ $labels.namespace }}`
            3. Review application configuration and dependencies
          
          runbook_url: "https://kubernetes.io/docs/tasks/debug-application-cluster/debug-application/"

      # Pod Restart Frequency Alert
      - alert: PodFrequentRestarts
        expr: rate(kube_pod_container_status_restarts_total[15m]) > 0.1
        for: 5m
        labels:
          severity: warning
          category: pod-health
          service: kubernetes
          team: platform
        annotations:
          summary: "‚ö†Ô∏è WARNING: Pod {{ $labels.pod }} is restarting frequently"
          description: |
            Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is restarting {{ $value | humanize }} times per second.
            
            **Namespace:** {{ $labels.namespace }}
            **Container:** {{ $labels.container }}
            **Node:** {{ $labels.node }}
            
            **Possible Causes:**
            - Application crashes
            - Resource constraints (CPU/Memory)
            - Health check failures
            - Configuration issues
            
            **Recommended Actions:**
            1. Check pod logs for error patterns
            2. Review resource limits and requests
            3. Verify health check configurations
          
          runbook_url: "https://kubernetes.io/docs/tasks/debug-application-cluster/debug-application/"

  - name: kubernetes-resource-alerts
    rules:
      # Node Memory Pressure Alert
      - alert: NodeMemoryPressure
        expr: kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
        for: 2m
        labels:
          severity: warning
          category: node-health
          service: kubernetes
          team: platform
        annotations:
          summary: "‚ö†Ô∏è WARNING: Node {{ $labels.node }} is under memory pressure"
          description: |
            Node {{ $labels.node }} is experiencing memory pressure.
            
            **Node:** {{ $labels.node }}
            **Condition:** MemoryPressure = true
            
            **Recommended Actions:**
            1. Check node memory usage: `kubectl top node {{ $labels.node }}`
            2. Review pod resource requests and limits
            3. Consider scaling the cluster or optimizing workloads
          
          runbook_url: "https://kubernetes.io/docs/tasks/debug-application-cluster/debug-cluster/"

      # Node Disk Pressure Alert
      - alert: NodeDiskPressure
        expr: kube_node_status_condition{condition="DiskPressure",status="true"} == 1
        for: 2m
        labels:
          severity: warning
          category: node-health
          service: kubernetes
          team: platform
        annotations:
          summary: "‚ö†Ô∏è WARNING: Node {{ $labels.node }} is under disk pressure"
          description: |
            Node {{ $labels.node }} is experiencing disk pressure.
            
            **Node:** {{ $labels.node }}
            **Condition:** DiskPressure = true
            
            **Recommended Actions:**
            1. Check node disk usage: `kubectl describe node {{ $labels.node }}`
            2. Clean up unused images and containers
            3. Consider increasing node storage capacity
          
          runbook_url: "https://kubernetes.io/docs/tasks/debug-application-cluster/debug-cluster/"
